{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03 - Recherche vectorielle avec Albert API\n",
    "\n",
    "**Objectif** : Impl√©menter la recherche s√©mantique sur le catalogue Mediatech\n",
    "\n",
    "**√âtapes** :\n",
    "1. Appeler Albert API pour g√©n√©rer l'embedding d'une question\n",
    "2. Calculer la similarit√© cosinus avec les embeddings Mediatech\n",
    "3. Retourner les top-k datasets pertinents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Configuration et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import httpx\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "ALBERT_API_KEY = os.getenv(\"ALBERT_API_KEY\")\n",
    "ALBERT_API_URL = os.getenv(\"ALBERT_API_URL\", \"https://albert.api.etalab.gouv.fr/v1\")\n",
    "\n",
    "if not ALBERT_API_KEY:\n",
    "    raise ValueError(\"ALBERT_API_KEY non d√©finie dans .env\")\n",
    "\n",
    "print(f\"‚úÖ Albert API configur√©e : {ALBERT_API_URL}\")\n",
    "print(f\"   Cl√© : {ALBERT_API_KEY[:20]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Charger les donn√©es Mediatech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion DuckDB\n",
    "PARQUET_GLOB = \"../huggingface/data_gouv_datasets_catalog_part_*.parquet\"\n",
    "con = duckdb.connect()\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE VIEW mediatech AS \n",
    "    SELECT * FROM read_parquet('{PARQUET_GLOB}')\n",
    "\"\"\")\n",
    "\n",
    "nb_datasets = con.execute(\"SELECT COUNT(*) FROM mediatech\").fetchone()[0]\n",
    "print(f\"‚úÖ {nb_datasets:,} datasets charg√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. Fonction d'embedding via Albert API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Appelle Albert API pour obtenir l'embedding BGE-M3 d'un texte.\n",
    "    Retourne un vecteur numpy de dimension 1024.\n",
    "    \"\"\"\n",
    "    url = f\"{ALBERT_API_URL}/embeddings\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {ALBERT_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"BAAI/bge-m3\",\n",
    "        \"input\": text\n",
    "    }\n",
    "    \n",
    "    with httpx.Client(timeout=30) as client:\n",
    "        response = client.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "    data = response.json()\n",
    "    embedding = data[\"data\"][0][\"embedding\"]\n",
    "    return np.array(embedding, dtype=np.float32)\n",
    "\n",
    "# Test\n",
    "test_emb = get_embedding(\"test\")\n",
    "print(f\"‚úÖ Embedding test : dimension {len(test_emb)}, type {test_emb.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 4. Charger les embeddings Mediatech en m√©moire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Charger tous les embeddings et m√©tadonn√©es\n",
    "# Note : ~99k embeddings de 1024 dim = ~400 MB en float32\n",
    "\n",
    "EMB_COL = \"embeddings_bge-m3\"\n",
    "\n",
    "df = con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        doc_id,\n",
    "        title,\n",
    "        organization,\n",
    "        description,\n",
    "        url,\n",
    "        quality_score,\n",
    "        metric_views,\n",
    "        \"{EMB_COL}\" as embedding_json\n",
    "    FROM mediatech\n",
    "    WHERE \"{EMB_COL}\" IS NOT NULL\n",
    "\"\"\").df()\n",
    "\n",
    "print(f\"‚úÖ {len(df):,} datasets avec embeddings charg√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Parser les embeddings JSON en matrice numpy\n",
    "# C'est l'√©tape la plus lente (~30s)\n",
    "\n",
    "embeddings_list = [json.loads(e) for e in df[\"embedding_json\"]]\n",
    "embeddings_matrix = np.array(embeddings_list, dtype=np.float32)\n",
    "\n",
    "print(f\"‚úÖ Matrice embeddings : {embeddings_matrix.shape}\")\n",
    "print(f\"   M√©moire : {embeddings_matrix.nbytes / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Fonction de recherche s√©mantique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(query_vec: np.ndarray, matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calcule la similarit√© cosinus entre un vecteur requ√™te et une matrice.\n",
    "    Retourne un vecteur de scores.\n",
    "    \"\"\"\n",
    "    # Normaliser le vecteur requ√™te\n",
    "    query_norm = query_vec / np.linalg.norm(query_vec)\n",
    "    \n",
    "    # Normaliser chaque ligne de la matrice\n",
    "    matrix_norms = np.linalg.norm(matrix, axis=1, keepdims=True)\n",
    "    matrix_normalized = matrix / matrix_norms\n",
    "    \n",
    "    # Produit scalaire = similarit√© cosinus (car vecteurs normalis√©s)\n",
    "    similarities = matrix_normalized @ query_norm\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_datasets(query: str, top_k: int = 10) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Recherche les datasets les plus pertinents pour une requ√™te.\n",
    "    \n",
    "    Args:\n",
    "        query: Question en langage naturel\n",
    "        top_k: Nombre de r√©sultats √† retourner\n",
    "        \n",
    "    Returns:\n",
    "        Liste de dicts avec les m√©tadonn√©es et scores\n",
    "    \"\"\"\n",
    "    # 1. Obtenir l'embedding de la requ√™te\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    # 2. Calculer les similarit√©s\n",
    "    similarities = cosine_similarity(query_embedding, embeddings_matrix)\n",
    "    \n",
    "    # 3. Trier et prendre les top-k\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    # 4. Construire les r√©sultats\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        row = df.iloc[idx]\n",
    "        results.append({\n",
    "            \"doc_id\": row[\"doc_id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"organization\": row[\"organization\"],\n",
    "            \"description\": row[\"description\"][:300] + \"...\" if row[\"description\"] and len(row[\"description\"]) > 300 else row[\"description\"],\n",
    "            \"url\": row[\"url\"],\n",
    "            \"quality_score\": row[\"quality_score\"],\n",
    "            \"metric_views\": row[\"metric_views\"],\n",
    "            \"similarity\": float(similarities[idx])\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Tests de recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1 : Requ√™te simple\n",
    "query = \"donn√©es sur la qualit√© de l'air en France\"\n",
    "print(f\"üîç Requ√™te : {query}\\n\")\n",
    "\n",
    "results = search_datasets(query, top_k=5)\n",
    "\n",
    "for i, r in enumerate(results, 1):\n",
    "    print(f\"{i}. [{r['similarity']:.3f}] {r['title']}\")\n",
    "    print(f\"   üìç {r['organization']}\")\n",
    "    print(f\"   üëÅÔ∏è {r['metric_views']:,} vues | ‚≠ê {r['quality_score']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2 : Autre requ√™te\n",
    "query = \"statistiques d√©mographiques par commune\"\n",
    "print(f\"üîç Requ√™te : {query}\\n\")\n",
    "\n",
    "results = search_datasets(query, top_k=5)\n",
    "\n",
    "for i, r in enumerate(results, 1):\n",
    "    print(f\"{i}. [{r['similarity']:.3f}] {r['title']}\")\n",
    "    print(f\"   üìç {r['organization']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3 : Requ√™te sp√©cifique\n",
    "query = \"bornes de recharge v√©hicules √©lectriques\"\n",
    "print(f\"üîç Requ√™te : {query}\\n\")\n",
    "\n",
    "results = search_datasets(query, top_k=5)\n",
    "\n",
    "for i, r in enumerate(results, 1):\n",
    "    print(f\"{i}. [{r['similarity']:.3f}] {r['title']}\")\n",
    "    print(f\"   üìç {r['organization']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 7. Optimisation : Pr√©-normaliser les embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©-normaliser pour acc√©l√©rer les recherches suivantes\n",
    "norms = np.linalg.norm(embeddings_matrix, axis=1, keepdims=True)\n",
    "embeddings_normalized = embeddings_matrix / norms\n",
    "\n",
    "def search_datasets_fast(query: str, top_k: int = 10) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Version optimis√©e avec embeddings pr√©-normalis√©s.\n",
    "    \"\"\"\n",
    "    # 1. Obtenir et normaliser l'embedding de la requ√™te\n",
    "    query_embedding = get_embedding(query)\n",
    "    query_norm = query_embedding / np.linalg.norm(query_embedding)\n",
    "    \n",
    "    # 2. Produit scalaire direct (embeddings d√©j√† normalis√©s)\n",
    "    similarities = embeddings_normalized @ query_norm\n",
    "    \n",
    "    # 3. Trier et prendre les top-k\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    # 4. Construire les r√©sultats\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        row = df.iloc[idx]\n",
    "        results.append({\n",
    "            \"doc_id\": row[\"doc_id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"organization\": row[\"organization\"],\n",
    "            \"description\": row[\"description\"][:300] + \"...\" if row[\"description\"] and len(row[\"description\"]) > 300 else row[\"description\"],\n",
    "            \"url\": row[\"url\"],\n",
    "            \"quality_score\": row[\"quality_score\"],\n",
    "            \"metric_views\": row[\"metric_views\"],\n",
    "            \"similarity\": float(similarities[idx])\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Embeddings pr√©-normalis√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Benchmark\n",
    "results = search_datasets_fast(\"transports en commun Paris\")\n",
    "print(f\"Top r√©sultat : {results[0]['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 8. R√©sum√©\n",
    "\n",
    "**Fonctions impl√©ment√©es** :\n",
    "- `get_embedding(text)` : Appel Albert API pour embedding BGE-M3\n",
    "- `search_datasets(query, top_k)` : Recherche s√©mantique sur Mediatech\n",
    "- `search_datasets_fast(query, top_k)` : Version optimis√©e\n",
    "\n",
    "**Performance** :\n",
    "- Chargement initial : ~30s (parsing JSON)\n",
    "- Recherche : ~200ms (dont ~150ms pour l'appel API)\n",
    "\n",
    "---\n",
    "\n",
    "## Prochaine √©tape\n",
    "\n",
    "**Notebook 04** : Client MCP datagouv\n",
    "- Se connecter au serveur MCP\n",
    "- R√©cup√©rer les donn√©es fra√Æches d'un dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
