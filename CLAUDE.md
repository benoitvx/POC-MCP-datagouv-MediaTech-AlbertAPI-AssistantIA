# CLAUDE.md - POC Application data.gouv

## Contexte projet

POC d'assistant IA pour rÃ©pondre en langage naturel sur les donnÃ©es publiques franÃ§aises.

**Architecture** :
```
Question utilisateur â†’ Embedding BGE-M3 (Albert API)
    â†’ Recherche vectorielle Mediatech â†’ dataset_id
    â†’ MCP datagouv â†’ donnÃ©es fraÃ®ches
    â†’ LLM Albert â†’ rÃ©ponse + sources
```

**Architecture hybride (recommandÃ©e aprÃ¨s POC)** :
```
Question utilisateur
    â†“
[Recherche Mediatech] â†’ dataset_id          # Recherche sÃ©mantique
    â†“
[MCP search/get_resource_info] â†’ URL CSV    # DÃ©couverte via MCP
    â†“
[HTTP direct / pandas] â†’ DataFrame          # TÃ©lÃ©chargement direct
    â†“
[LLM] â†’ analyse donnÃ©es + rÃ©ponse           # Analyse avec contexte complet
```

âš ï¸ **Limitation MCP dÃ©couverte** : `query_resource_data` et `download_and_parse_resource`
retournent seulement ~3 lignes d'exemple, quel que soit le `page_size` demandÃ©.

## Stack technique

- **Python** : notebooks Jupyter (pas de TypeScript pour ce projet)
- **DuckDB** : requÃªtes SQL sur Parquet
- **httpx** : appels API (Albert, MCP)
- **Parquet** : catalogue Mediatech (~99k datasets, embeddings BGE-M3 1024 dim)

## Ressources externes

- Mediatech : `AgentPublic/data-gouv-datasets-catalog` sur HuggingFace
- MCP datagouv : `https://mcp.data.gouv.fr/mcp` (Streamable HTTP, JSON-RPC)
- Albert API : endpoint OpenAI-compatible, clÃ© dans `.env`

## Structure projet

```
poc-datagouv/
â”œâ”€â”€ notebooks/          # DÃ©veloppement itÃ©ratif
â”‚   â”œâ”€â”€ 01_setup_test.ipynb         # Configuration et tests
â”‚   â”œâ”€â”€ 02_mediatech_exploration.ipynb  # Exploration donnÃ©es
â”‚   â”œâ”€â”€ 03_vector_search.ipynb      # Recherche sÃ©mantique
â”‚   â”œâ”€â”€ 04_mcp_client.ipynb         # Client MCP datagouv
â”‚   â”œâ”€â”€ 05_orchestration.ipynb      # Pipeline complet
â”‚   â”œâ”€â”€ 06_demo.ipynb               # Interface interactive
â”‚   â””â”€â”€ 07_text_to_query.ipynb      # Text-to-query (extraction donnÃ©es)
â”œâ”€â”€ huggingface/        # Parquet Mediatech tÃ©lÃ©chargÃ©
â”œâ”€â”€ data/               # DonnÃ©es locales (gitignore)
â””â”€â”€ .env                # ALBERT_API_KEY (gitignore)
```

## Conventions

- **Code commentÃ© en franÃ§ais**
- **Validation Ã©tape par Ã©tape** : chaque cellule doit fonctionner avant de passer Ã  la suivante
- **Notebooks = exploration**, `src/` = code propre extrait des notebooks
- Commits : emoji + description concise

## Commandes utiles

```bash
# Activer l'environnement
source .venv/bin/activate

# Lancer Jupyter
jupyter lab

# Tester les imports
python -c "import duckdb, httpx, pandas; print('OK')"
```

## Variables d'environnement

```
ALBERT_API_KEY=xxx          # Requis
ALBERT_API_URL=https://albert.api.etalab.gouv.fr  # Par dÃ©faut
```

## Notes techniques

### Mediatech
- Colonne embeddings : `embeddings_bge-m3` (vecteurs 1024 dim, FLOAT[])
- GranularitÃ© : chunks (plusieurs par dataset), `doc_id` = identifiant dataset unique
- ~280k chunks pour ~99k datasets

### Albert API
- **Embeddings** : `BAAI/bge-m3` â†’ vecteur 1024 dim
- **LLM** : `mistralai/Mistral-Small-3.2-24B-Instruct-2506` (alias: albert-large)
- Endpoint : `/v1/embeddings`, `/v1/chat/completions` (OpenAI-compatible)

### MCP datagouv
- Transport : Streamable HTTP (POST JSON-RPC)
- Headers requis : `Accept: application/json, text/event-stream`, `http2=False`
- Session : Header `Mcp-Session-Id` retournÃ© aprÃ¨s `initialize`
- RÃ©ponses en SSE (Server-Sent Events), texte formatÃ© (pas JSON structurÃ©)

**Tools disponibles** :
| Tool | Usage | Status |
|------|-------|--------|
| `search_datasets` | Recherche par mots-clÃ©s | âœ… OK |
| `get_dataset_info` | MÃ©tadonnÃ©es dataset | âœ… OK |
| `list_dataset_resources` | Liste des fichiers | âœ… OK |
| `get_resource_info` | URL + schÃ©ma ressource | âœ… OK |
| `get_metrics` | Stats d'usage | âœ… OK |
| `query_resource_data` | Extraction donnÃ©es | âš ï¸ LimitÃ© Ã  3 lignes |
| `download_and_parse_resource` | TÃ©lÃ©chargement + parsing | âš ï¸ LimitÃ© Ã  3 lignes |

**Limitation connue** : Les tools d'extraction de donnÃ©es retournent toujours
"Sample data (first 3 rows)" dans la rÃ©ponse texte, indÃ©pendamment du `page_size`.
â†’ Workaround : rÃ©cupÃ©rer l'URL via `get_resource_info` puis tÃ©lÃ©charger directement.

### Text-to-Query (notebook 07)
- **Objectif** : Passer de "trouver le bon dataset" Ã  "extraire les donnÃ©es pertinentes"
- **ParamÃ¨tres `query_resource_data`** :
  - `resource_id` (requis) : ID de la ressource
  - `question` (requis) : Question en langage naturel (âš ï¸ informatif seulement, ne filtre pas)
  - `page`, `page_size` : Pagination (mais rÃ©ponse texte limitÃ©e Ã  3 lignes)
- **Conclusion** : Le paramÃ¨tre `question` ne filtre pas les donnÃ©es cÃ´tÃ© serveur.
  L'API retourne toujours les mÃªmes donnÃ©es brutes paginÃ©es.
- **Solution retenue** : Architecture hybride (MCP pour dÃ©couverte, HTTP pour donnÃ©es)

## Roadmap

1. âœ… Setup environnement
2. âœ… Exploration Mediatech (99k datasets, 40 colonnes)
3. âœ… Recherche vectorielle (Albert embeddings + cosine similarity)
4. âœ… Client MCP datagouv (JSON-RPC sur SSE)
5. âœ… Orchestration LLM (pipeline question â†’ rÃ©ponse)
6. âœ… Interface interactive (ipywidgets)
7. âœ… Text-to-Query (exploration + architecture hybride documentÃ©e)

## Utilisation

```bash
# Lancer la dÃ©mo
source .venv/bin/activate
jupyter lab
# Ouvrir notebooks/06_demo.ipynb et exÃ©cuter toutes les cellules
```

## Conclusions POC

**Ce qui fonctionne bien** :
- Recherche sÃ©mantique Mediatech (99k datasets, ~135ms/requÃªte)
- MCP pour la dÃ©couverte (search, metadata, URLs)
- Pipeline RAG avec Albert LLM
- Interface interactive ipywidgets

**Limitation identifiÃ©e** :
- MCP `query_resource_data` retourne seulement 3 lignes d'exemple
- Question en attente auprÃ¨s du mainteneur MCP data.gouv

**Architecture recommandÃ©e** :
```
MCP (dÃ©couverte) + HTTP direct (donnÃ©es) + LLM (analyse)
```

## Prochaines Ã©tapes

1. â³ Attendre retour du mainteneur MCP sur la limitation des 3 lignes
2. ğŸ“¦ Extraire le code des notebooks vers `src/` si le POC Ã©volue en projet
3. ğŸ”„ Tester avec d'autres datasets (diffÃ©rents formats, tailles)
4. ğŸ¨ AmÃ©liorer l'interface (Streamlit ou Gradio pour une vraie dÃ©mo)
